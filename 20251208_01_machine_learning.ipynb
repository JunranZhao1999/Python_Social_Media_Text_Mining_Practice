{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80785a9-e10e-4df5-aad4-9201bfd26365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "weibo_df = pd.read_excel('weibo_data.xlsx')\n",
    "corpus = []\n",
    "for i in range(1,len(weibo_df)):\n",
    "    corpus.append(weibo_df.iloc[i,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb627b6-c9ea-459f-95f1-e84db4edfee5",
   "metadata": {},
   "source": [
    "#### TF-IDF + 传统机器学习（SVM, Random Forest）适用于简单分类任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32a0fbf3-b224-4f98-b851-d440fff05410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_model_prediction:  [1]\n",
      "rf_model_prediction:  [0]\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 示例数据\n",
    "corpus = [\n",
    "    \"这部电影很好看，我非常喜欢。\",\n",
    "    \"剧情很感人，演员演技也很棒。\",\n",
    "    \"太无聊了，浪费时间。\",\n",
    "    \"这是一部烂片，后悔看了。\",\n",
    "    \"非常精彩的故事，推荐观看。\",\n",
    "    \"不值得看，情节太差了。\"\n",
    "]\n",
    "\n",
    "# 自己打标签 - 现在有一些好的训练集是自己带标签的\n",
    "labels = [1, 1, 0, 0, 1, 0]  # 1 代表好评，0 代表差评\n",
    "\n",
    "# 中文分词\n",
    "corpus_text = [' '.join(jieba.cut(text)) for text in corpus]\n",
    "\n",
    "# tf-idf(list)\n",
    "vectorizer = TfidfVectorizer()  # list\n",
    "X = vectorizer.fit_transform(corpus_text)\n",
    "\n",
    "# 训练 SVM 分类器 - 适用于二分类\n",
    "svm_model = SVC(kernel = 'linear')\n",
    "svm_model.fit(X,labels)\n",
    "\n",
    "# 训练 Random Forest 分类器 - 适用于二分类和多分类\n",
    "rf_model = RandomForestClassifier(n_estimators = 100,\n",
    "                                      max_depth = 10,\n",
    "                                      random_state = 42)\n",
    "rf_model.fit(X,labels)\n",
    "\n",
    "# prediction\n",
    "test_text = '这部电影真的太棒了！'\n",
    "text_vector = vectorizer.transform([' '.join(jieba.cut(test_text))])\n",
    "print('svm_model_prediction: ',svm_model.predict(text_vector))\n",
    "print('rf_model_prediction: ',rf_model.predict(text_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e629ee-9df2-43f1-9fdf-8a40c75c5559",
   "metadata": {},
   "source": [
    "#### Word2Vec 可提供更丰富的语义信息，在低资源条件下表现良好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9bb6806-61ea-4082-aebe-2eaa55aac313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 预测结果: [1]\n",
      "Random Forest 预测结果: [1]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "### ---Word2Vec 模型训练---\n",
    "\n",
    "# 准备输入格式： \n",
    "# corpus_cut_list 将原始文本列表转换成 词语列表的列表（即 [['这', '部', '电影', '很', '好看'], ['剧情', '很', '感人'], ...]）。这是 Word2Vec 模型要求的输入格式。\n",
    "corpus_cut_list = [list(jieba.cut(text)) for text in corpus]\n",
    "\n",
    "# 训练Word2Vec模型\n",
    "word2vec_model = Word2Vec(sentences = corpus_cut_list, # 传入训练数据\n",
    "                          vector_size = 100, # 设置每个词语将被表示成一个 100 维的向量（词向量的维度）\n",
    "                          window = 5, # 设定模型在训练时会考虑一个词语前后 5 个词语的上下文\n",
    "                          min_count = 1, # 要求词语至少出现 1 次才会被纳入词汇表\n",
    "                          workers = 4) # 使用 4 个 CPU 核心进行并行训练，加速过程\n",
    "# 训练完成后，word2vec_model 内部存储了每个词语（如 '电影', '好看', '无聊'）对应的 100 维数值向量。\n",
    "\n",
    "### ---定义句子向量计算函数---\n",
    "\n",
    "# 计算句子向量\n",
    "# Word2Vec 直接生成词语的向量，而我们的分类器需要整个句子的向量。这个函数实现了从词向量到句子向量的转换\n",
    "def get_sentence_vector(sentence,model):\n",
    "    # 1.分词： 对输入句子进行分词。\n",
    "    words = list(jieba.cut(sentence))\n",
    "    \n",
    "    # 2.提取词向量： 遍历分词结果，从 Word2Vec 模型的词汇表 (model.wv) 中提取每个词对应的 100 维向量。\n",
    "    vectors = [model.wv[word] for word in words if word in model.wv]\n",
    "    # model.wv 是 Gensim Word2Vec 模型的一个关键属性，它代表 Word Vectors（词向量）。\n",
    "    # model.wv['电影'] -> 返回一个 100 维 NumPy 数组\n",
    "    \n",
    "    # 3.平均求和 (Averaging)： 将句子中所有词的词向量进行求平均。这个平均向量（也是 100 维）就被用来代表整个句子的语义特征。\n",
    "    # 注意： 如果句子为空或所有词都不在词汇表中，则返回一个 100 维的零向量。\n",
    "    return np.mean(vectors,axis = 0) if vectors else np.zeros(100)\n",
    "\n",
    "### ---训练数据特征转换与模型训练---\n",
    "\n",
    "# 单一的、统一的二维 NumPy 矩阵\n",
    "# 最外层的 np.array() 的作用是：将列表推导式生成的一系列独立的 100 维 NumPy 数组（即每个句子的向量），聚合 成一个单一的、统一的二维 NumPy 矩阵，以供 Scikit-learn 分类器 (SVM, Random Forest) 使用。\n",
    "X_train_vectors = np.array([get_sentence_vector(text,word2vec_model) for text in corpus])\n",
    "\n",
    "# 训练 SVM\n",
    "svm_model.fit(X_train_vectors, labels)\n",
    "# 训练随机森林\n",
    "rf_model.fit(X_train_vectors, labels)\n",
    "\n",
    "\n",
    "# 预测\n",
    "test_vector = get_sentence_vector(test_text, word2vec_model).reshape(1, -1)\n",
    "# .reshape(1, -1) 是必要的，因为它将单个向量从 $(100,)$ 形状调整为 $(1, 100)$，以符合 predict 函数对输入格式的要求\n",
    "print(\"SVM 预测结果:\", svm_model.predict(test_vector))\n",
    "print(\"Random Forest 预测结果:\", rf_model.predict(test_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511a765c-d016-49fe-be71-1fbb4ecd7686",
   "metadata": {},
   "source": [
    "#### BERT 适用于更复杂的 NLP 任务，能够理解更深层次的语义关系。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a2eda42-50aa-4f50-b8a6-1bb6710656d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py39/lib/python3.9/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at hfl/chinese-bert-wwm were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 预测结果: [1]\n",
      "Random Forest 预测结果: [1]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# 加载中文 BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('hfl/chinese-bert-wwm')\n",
    "bert_model = BertModel.from_pretrained('hfl/chinese-bert-wwm')\n",
    "\n",
    "# 获取句子 BERT 向量\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text,\n",
    "                       return_tensors = 'pt',\n",
    "                       padding = True,\n",
    "                       truncation = True,\n",
    "                       max_length = 512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().numpy()  # 取 [CLS] token 的向量\n",
    "\n",
    "# 计算训练集向量\n",
    "X_train_bert = np.array([get_bert_embedding(text) for text in corpus])\n",
    "\n",
    "# 训练 SVM\n",
    "svm_model.fit(X_train_bert,labels)\n",
    "# 训练随机森林\n",
    "rf_model.fit(X_train_bert, labels)\n",
    "\n",
    "# perdict\n",
    "test_vector = get_bert_embedding(test_text).reshape(1,-1)\n",
    "# get_bert_embedding(test_text) 的原始输出：这个函数返回的是单个句子的嵌入向量，它是一个 一维 NumPy 数组，形状为 $(768,)$。\n",
    "# predict() 函数的要求：Scikit-learn 的 predict() 函数始终期望其输入是一个二维数组，即使你只预测一个样本。它要求输入形状为 $(\\text{n\\_samples}, \\text{n\\_features})$。\n",
    "# reshape(1, -1) 的作用：它将原始的 $(768,)$ 一维数组 转换成一个 二维数组，形状变为 $(1, 768)$。\n",
    "#     这里的 $1$ 代表 1 个样本（即您的测试文本）。\n",
    "#     这里的 $-1$ 是一个通配符，它告诉 NumPy 自动计算出该维度的大小，即 $768$ 个特征。\n",
    "print(\"SVM 预测结果:\", svm_model.predict(test_vector))\n",
    "print(\"Random Forest 预测结果:\", rf_model.predict(test_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c052e72-d267-4369-b4aa-f0b7c7f9dd74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
